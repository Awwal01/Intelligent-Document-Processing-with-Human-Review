{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef88a6dc-2b2b-4126-aba5-3dc7af1b3af6",
   "metadata": {},
   "source": [
    "# Intelligent Document Processing for Document Classification with Human Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36548152-2d80-4215-a13b-86326a984926",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Intelligent Document Processing\n",
    "Intelligent Document Processing (IDP) is the automation of manual document processing tasks. IDP usually involves using machine learning solutions to automate tasks such as extracting text from images or other legacy documents and performing business processing tasks on extracted text, such as document classification from the content of documents.\n",
    "\n",
    "AWS Definition of IDP - Intelligent document processing (IDP) is automating the process of manual data entry from paper-based documents or document images to integrate with other digital business processes.\n",
    "\n",
    "Augmented Intelligence - This is used to improve accuracy of machine learning tasks by including humans verify classification outputs based on rules it minimize misclassification in edge cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa81c11-65c8-4926-898e-852408f09732",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "In this lab we will walk through a hands-on lab on document classification using Amazon Comprehend\n",
    "Custom Classifier. We will use Amazon Textract to extract the text from documents, label the documents, use text and data for training our Amazon comprehend custom classifier. We use Amazon Comprehend Analysis job to perform batch analysis for our document classification, and sent documents where classification confidence fell below a set threshold for a to human review.\n",
    "\n",
    "![IDP Classify](./images/IDP-ARC-Diag-2.png)\n",
    "\n",
    "- [Step 1: Setup notebook and upload sample documents to Amazon S3](#step1)\n",
    "- [Step 2: Extract text from sample documents using Amazon Textract](#step2)\n",
    "- [Step 3: Prepare a CSV training dataset for Amazon Comprehend custom classifier training](#step3)\n",
    "- [Step 4: Create Amazon Comprehend Classification training job](#step4)\n",
    "- [Step 5: Classify documents with Amazon Comprehend custom classifier](#step5)\n",
    "- [Step 6: Amazon Augmented AI](#step6)\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a2d5e-29ec-4546-b782-f42699de5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install Latest SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e030f6-4bef-4e53-9c8e-759a952bfc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "Successfully installed pip-24.0\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.28.64)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.56 (from boto3)\n",
      "  Downloading botocore-1.34.56-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.56->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.56->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.56->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.56-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.56-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.64\n",
      "    Uninstalling botocore-1.31.64:\n",
      "      Successfully uninstalled botocore-1.31.64\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.7.0\n",
      "    Uninstalling s3transfer-0.7.0:\n",
      "      Successfully uninstalled s3transfer-0.7.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.64\n",
      "    Uninstalling boto3-1.28.64:\n",
      "      Successfully uninstalled boto3-1.28.64\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.56 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.56 botocore-1.34.56 s3transfer-0.10.0\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.10/site-packages (1.34.56)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8813450-a6cf-4370-b589-fca6c816f8d6",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We need to set up the following data:\n",
    "* `region` - Region to call A2I\n",
    "* `bucket` - A S3 bucket accessible by the given role\n",
    "    * Used to store the sample images & output results\n",
    "    * Must be within the same region A2I is called from\n",
    "* `role` - The IAM role used as part of StartHumanLoop. By default, this notebook will use the execution role\n",
    "* `workteam` - Group of people to send the work to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa4ac3-295e-447f-a2da-aa4797d44b47",
   "metadata": {},
   "source": [
    "### Role and Permissions\n",
    "\n",
    "The AWS IAM Role used to execute the notebook needs to have the following permissions:\n",
    "\n",
    "* ComprehendFullAccess\n",
    "* SagemakerFullAccess\n",
    "* IAMReadOnlyAccess\n",
    "* AmazonS3FullAccess\n",
    "* Inline policy (Comprehend-passrole)\n",
    "\n",
    "Click in the under `permissions` in the add `Add Permissions` drop down select `Create Inline Policy`\n",
    "Select `Json` on the `Specify permissions` page and paste the following code\n",
    "```\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": \"iam:PassRole\",\n",
    "\t\t\t\"Resource\": \"arn:aws:iam::*:role/*\",\n",
    "\t\t\t\"Condition\": {\n",
    "\t\t\t\t\"StringEquals\": {\n",
    "\t\t\t\t\t\"iam:PassedToService\": [\n",
    "\t\t\t\t\t\t\"comprehend.amazonaws.com\"\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "```\n",
    "Then click `Next` button\n",
    "click `Save Changes` On the `Review and Save Changes` page \n",
    "You can read this blog to learn more about IAM pass roles https://aws.amazon.com/blogs/security/how-to-use-the-passrole-permission-with-iam-roles/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3d583-6f72-47e6-8f2f-74ae4e26ae04",
   "metadata": {},
   "source": [
    "# Step 1: Setup notebook and upload  sample documents to Amazon S3 <a id=\"step1\"></a>\n",
    "\n",
    "In this step, we will import some necessary libraries that will be used throughout this notebook. We will then upload all the documents from the `/classification-training` folder to SageMaker's default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54541627-e04e-48ef-802e-4b6a5e447f4e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install -q amazon-textract-response-parser --upgrade\n",
    "!python -m pip install -q amazon-textract-caller --upgrade\n",
    "!python -m pip install -q amazon-textract-prettyprinter --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9ec539-f6fe-4576-b3ac-a47309af21e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Setting Role to the default SageMaker Execution Role\n",
    "ROLE = get_execution_role()\n",
    "\n",
    "from textractcaller.t_call import call_textract, Textract_Features\n",
    "from textractprettyprinter.t_pretty_print import Textract_Pretty_Print, get_string\n",
    "from trp import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a92387-6805-4673-88a6-138a94f14761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "from IPython.display import Image, display, HTML, JSON\n",
    "\n",
    "# variables\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "os.environ[\"BUCKET\"] = data_bucket\n",
    "os.environ[\"REGION\"] = region\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "textract = boto3.client('textract', region_name=region)\n",
    "comprehend=boto3.client('comprehend', region_name=region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0feb97-cb50-4c6b-81b2-4341f6be4519",
   "metadata": {},
   "source": [
    "### Download and Unzip the sample data `classification-training.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621d1f68-b6bb-47a4-9c2b-f0b1faebbb86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 21.0M  100 21.0M    0     0  46.5M      0 --:--:-- --:--:-- --:--:-- 46.4M\n"
     ]
    }
   ],
   "source": [
    "!curl https://idp-assets-wwso.s3.us-east-2.amazonaws.com/workshop-data/classification-training.zip --output classification-training.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8414a4-1180-48ce-af50-05ee328ff523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document archive extracted successfully...\n",
      "Removing hidden files/directories: ./classification-training/receipts/.ipynb_checkpoints\n",
      "Removing hidden files/directories: ./classification-training/invoices/.DS_Store\n",
      "Removing hidden files/directories: ./classification-training/invoices/.ipynb_checkpoints\n",
      "Removing hidden files/directories: ./classification-training/bank-statements/.DS_Store\n",
      "Removing hidden files/directories: ./classification-training/bank-statements/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.unpack_archive(\"./classification-training.zip\", extract_dir=\"classification-training\")\n",
    "    print(\"Document archive extracted successfully...\")\n",
    "    for path, subdirs, files in os.walk('./classification-training'):\n",
    "        for name in files:\n",
    "            if name.startswith('.'):\n",
    "                hidden = os.path.join(path, name)\n",
    "                print(f'Removing hidden files/directories: {hidden}')\n",
    "                os.system(f\"rm -rf {hidden}\")\n",
    "        for dirs in subdirs:\n",
    "            if dirs.startswith('.'):\n",
    "                if dirs.startswith('.'):\n",
    "                    hidden = os.path.join(path, dirs)\n",
    "                    print(f'Removing hidden files/directories: {hidden}')\n",
    "                    os.system(f\"rm -rf {hidden}\")\n",
    "except Exception as e:\n",
    "    print(\"Please upload the document zip file classification-training.zip\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a44576-5267-410a-a6b5-cebb9dea1425",
   "metadata": {},
   "source": [
    "### Upload sample data to S3 bucket\n",
    "\n",
    "The sample documents are in `/classification-training` directory. For this workshop, we will be using sample bank statements, invoices, and receipts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61751e21-cfe6-4795-9972-b6707b24e062",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload images to S3 bucket:\n",
    "!aws s3 cp classification-training s3://{data_bucket}/idp/textract --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97ccb4-706c-47bf-9494-0a230967ff7f",
   "metadata": {},
   "source": [
    "### Validate the documents in S3\n",
    "\n",
    "We will create a small utility function to verify that our documents have been uploaded to the S3 bucket. This function will also be used to collect the document paths (S3 keys) into an array that we will user later to extract text using Amazon Textract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2ab5ae-386b-4034-a9b1-085179878464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_bucket_items(bucket, prefix, start_after):\n",
    "    list_items=[]\n",
    "    \n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    operation_parameters = {'Bucket': bucket,\n",
    "                            'Prefix': prefix,\n",
    "                            'StartAfter':start_after}\n",
    "    page_iterator = paginator.paginate(**operation_parameters)\n",
    "    for page in page_iterator:\n",
    "        for item in page['Contents']:\n",
    "            list_items.append(item['Key'])\n",
    "    names=list(set([os.path.dirname(x)+'/' for x in list_items]))\n",
    "    images=[x for x in list_items if x not in names and '.ipynb_checkpoints' not in x ]\n",
    "    names=[x.replace(prefix,'').strip('/') for x in names if  '.ipynb_checkpoints' not in x]\n",
    "    return list_items, names, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf78a3-4505-430e-b614-6a8109391b8d",
   "metadata": {},
   "source": [
    "list some documents uploaded to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed07171f-b46c-4aad-a53f-3992f55b59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "\n",
    "train_objects, names, train_images=get_s3_bucket_items(data_bucket, 'idp/textract', 'idp/textract/') \n",
    "docs.append(train_images)\n",
    "\n",
    "if type(docs[0]) is list:\n",
    "    docs=[item for sublist in docs for item in sublist]\n",
    "    \n",
    "names, docs[-10:], docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9a09b-3734-407a-a01c-508cd731a28e",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Extract text from sample documents using Amazon Textract and label<a id=\"step2\"></a>\n",
    "\n",
    "In this section we  use Amazon Textract's `detect_document_text` API to extract the raw text information for all the documents in S3. We will also label the data according to the document type. This labeled data will be used to train a custom Amazon Comprehend classifier. We define a utility function that uses the `textract_extract_text` API to extract text from a document and find which category (or directory in S3) it belongs to and then label the data and return an array `[<label>, <document_text>]`. \n",
    "\n",
    "In order to extract text from a document using textract we use the `DetectDocumentText` API. You can use the Boto3 version of the API as `textract.detect_document_text`, however in this notebook we will use the `call_textract` tool that we installed earlier in the Notebook ([refer to `amazon-textract-caller`](https://pypi.org/project/amazon-textract-caller/) for more info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d450259b-b037-4ce6-9333-f4f14638224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textract_extract_text(document, bucket=data_bucket):        \n",
    "    try:\n",
    "        print(f'Processing document: {document}')\n",
    "        lines = \"\"\n",
    "        row = []\n",
    "        \n",
    "        # using amazon-textract-caller\n",
    "        response = call_textract(input_document=f's3://{bucket}/{document}') \n",
    "        # using pretty printer to get all the lines\n",
    "        lines = get_string(textract_json=response, output_type=[Textract_Pretty_Print.LINES])\n",
    "        \n",
    "        label = [name for name in names if(name in document)]  \n",
    "        row.append(label[0])\n",
    "        row.append(lines)        \n",
    "        return row\n",
    "    except Exception as e:\n",
    "        print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f29fdc07-290c-4390-873c-95525cf69644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document: idp/textract/bank-statements/bank_stmt_0.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_1.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_10.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_11.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_12.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_13.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_14.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_15.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_16.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_17.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_18.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_19.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_2.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_20.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_21.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_22.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_23.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_24.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_25.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_26.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_27.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_28.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_29.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_3.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_30.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_31.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_32.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_33.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_34.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_35.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_36.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_37.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_38.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_39.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_4.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_40.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_41.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_42.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_43.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_44.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_45.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_46.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_47.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_48.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_49.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_5.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_50.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_51.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_52.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_53.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_54.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_55.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_56.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_57.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_58.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_59.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_6.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_60.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_61.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_62.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_63.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_64.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_65.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_66.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_67.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_68.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_69.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_7.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_70.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_71.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_72.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_73.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_74.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_75.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_76.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_77.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_78.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_79.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_8.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_80.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_81.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_82.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_83.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_84.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_85.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_86.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_87.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_88.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_89.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_9.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_90.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_91.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_92.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_93.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_94.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_95.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_96.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_97.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_98.png\n",
      "Processing document: idp/textract/bank-statements/bank_stmt_99.png\n",
      "Processing document: idp/textract/invoices/invoice_0.png\n",
      "Processing document: idp/textract/invoices/invoice_1.png\n",
      "Processing document: idp/textract/invoices/invoice_10.png\n",
      "Processing document: idp/textract/invoices/invoice_11.png\n",
      "Processing document: idp/textract/invoices/invoice_12.png\n",
      "Processing document: idp/textract/invoices/invoice_13.png\n",
      "Processing document: idp/textract/invoices/invoice_14.png\n",
      "Processing document: idp/textract/invoices/invoice_15.png\n",
      "Processing document: idp/textract/invoices/invoice_16.png\n",
      "Processing document: idp/textract/invoices/invoice_17.png\n",
      "Processing document: idp/textract/invoices/invoice_18.png\n",
      "Processing document: idp/textract/invoices/invoice_19.png\n",
      "Processing document: idp/textract/invoices/invoice_2.png\n",
      "Processing document: idp/textract/invoices/invoice_20.png\n",
      "Processing document: idp/textract/invoices/invoice_21.png\n",
      "Processing document: idp/textract/invoices/invoice_22.png\n",
      "Processing document: idp/textract/invoices/invoice_23.png\n",
      "Processing document: idp/textract/invoices/invoice_24.png\n",
      "Processing document: idp/textract/invoices/invoice_25.png\n",
      "Processing document: idp/textract/invoices/invoice_26.png\n",
      "Processing document: idp/textract/invoices/invoice_27.png\n",
      "Processing document: idp/textract/invoices/invoice_28.png\n",
      "Processing document: idp/textract/invoices/invoice_29.png\n",
      "Processing document: idp/textract/invoices/invoice_3.png\n",
      "Processing document: idp/textract/invoices/invoice_30.png\n",
      "Processing document: idp/textract/invoices/invoice_31.png\n",
      "Processing document: idp/textract/invoices/invoice_32.png\n",
      "Processing document: idp/textract/invoices/invoice_33.png\n",
      "Processing document: idp/textract/invoices/invoice_34.png\n",
      "Processing document: idp/textract/invoices/invoice_35.png\n",
      "Processing document: idp/textract/invoices/invoice_36.png\n",
      "Processing document: idp/textract/invoices/invoice_37.png\n",
      "Processing document: idp/textract/invoices/invoice_38.png\n",
      "Processing document: idp/textract/invoices/invoice_39.png\n",
      "Processing document: idp/textract/invoices/invoice_4.png\n",
      "Processing document: idp/textract/invoices/invoice_40.png\n",
      "Processing document: idp/textract/invoices/invoice_41.png\n",
      "Processing document: idp/textract/invoices/invoice_42.png\n",
      "Processing document: idp/textract/invoices/invoice_43.png\n",
      "Processing document: idp/textract/invoices/invoice_44.png\n",
      "Processing document: idp/textract/invoices/invoice_45.png\n",
      "Processing document: idp/textract/invoices/invoice_46.png\n",
      "Processing document: idp/textract/invoices/invoice_47.png\n",
      "Processing document: idp/textract/invoices/invoice_48.png\n",
      "Processing document: idp/textract/invoices/invoice_49.png\n",
      "Processing document: idp/textract/invoices/invoice_5.png\n",
      "Processing document: idp/textract/invoices/invoice_50.png\n",
      "Processing document: idp/textract/invoices/invoice_51.png\n",
      "Processing document: idp/textract/invoices/invoice_52.png\n",
      "Processing document: idp/textract/invoices/invoice_53.png\n",
      "Processing document: idp/textract/invoices/invoice_54.png\n",
      "Processing document: idp/textract/invoices/invoice_55.png\n",
      "Processing document: idp/textract/invoices/invoice_56.png\n",
      "Processing document: idp/textract/invoices/invoice_57.png\n",
      "Processing document: idp/textract/invoices/invoice_58.png\n",
      "Processing document: idp/textract/invoices/invoice_59.png\n",
      "Processing document: idp/textract/invoices/invoice_6.png\n",
      "Processing document: idp/textract/invoices/invoice_60.png\n",
      "Processing document: idp/textract/invoices/invoice_61.png\n",
      "Processing document: idp/textract/invoices/invoice_62.png\n",
      "Processing document: idp/textract/invoices/invoice_63.png\n",
      "Processing document: idp/textract/invoices/invoice_64.png\n",
      "Processing document: idp/textract/invoices/invoice_65.png\n",
      "Processing document: idp/textract/invoices/invoice_66.png\n",
      "Processing document: idp/textract/invoices/invoice_67.png\n",
      "Processing document: idp/textract/invoices/invoice_68.png\n",
      "Processing document: idp/textract/invoices/invoice_69.png\n",
      "Processing document: idp/textract/invoices/invoice_7.png\n",
      "Processing document: idp/textract/invoices/invoice_70.png\n",
      "Processing document: idp/textract/invoices/invoice_71.png\n",
      "Processing document: idp/textract/invoices/invoice_72.png\n",
      "Processing document: idp/textract/invoices/invoice_73.png\n",
      "Processing document: idp/textract/invoices/invoice_74.png\n",
      "Processing document: idp/textract/invoices/invoice_75.png\n",
      "Processing document: idp/textract/invoices/invoice_76.png\n",
      "Processing document: idp/textract/invoices/invoice_77.png\n",
      "Processing document: idp/textract/invoices/invoice_78.png\n",
      "Processing document: idp/textract/invoices/invoice_79.png\n",
      "Processing document: idp/textract/invoices/invoice_8.png\n",
      "Processing document: idp/textract/invoices/invoice_80.png\n",
      "Processing document: idp/textract/invoices/invoice_81.png\n",
      "Processing document: idp/textract/invoices/invoice_82.png\n",
      "Processing document: idp/textract/invoices/invoice_83.png\n",
      "Processing document: idp/textract/invoices/invoice_84.png\n",
      "Processing document: idp/textract/invoices/invoice_85.png\n",
      "Processing document: idp/textract/invoices/invoice_86.png\n",
      "Processing document: idp/textract/invoices/invoice_87.png\n",
      "Processing document: idp/textract/invoices/invoice_88.png\n",
      "Processing document: idp/textract/invoices/invoice_89.png\n",
      "Processing document: idp/textract/invoices/invoice_9.png\n",
      "Processing document: idp/textract/invoices/invoice_90.png\n",
      "Processing document: idp/textract/invoices/invoice_91.png\n",
      "Processing document: idp/textract/invoices/invoice_92.png\n",
      "Processing document: idp/textract/invoices/invoice_93.png\n",
      "Processing document: idp/textract/invoices/invoice_94.png\n",
      "Processing document: idp/textract/invoices/invoice_95.png\n",
      "Processing document: idp/textract/invoices/invoice_96.png\n",
      "Processing document: idp/textract/invoices/invoice_97.png\n",
      "Processing document: idp/textract/invoices/invoice_98.png\n",
      "Processing document: idp/textract/invoices/invoice_99.png\n",
      "Processing document: idp/textract/receipts/receipt_0.png\n",
      "Processing document: idp/textract/receipts/receipt_1.png\n",
      "Processing document: idp/textract/receipts/receipt_10.png\n",
      "Processing document: idp/textract/receipts/receipt_11.png\n",
      "Processing document: idp/textract/receipts/receipt_12.png\n",
      "Processing document: idp/textract/receipts/receipt_13.png\n",
      "Processing document: idp/textract/receipts/receipt_14.png\n",
      "Processing document: idp/textract/receipts/receipt_15.png\n",
      "Processing document: idp/textract/receipts/receipt_16.png\n",
      "Processing document: idp/textract/receipts/receipt_17.png\n",
      "Processing document: idp/textract/receipts/receipt_18.png\n",
      "Processing document: idp/textract/receipts/receipt_19.png\n",
      "Processing document: idp/textract/receipts/receipt_2.png\n",
      "Processing document: idp/textract/receipts/receipt_20.png\n",
      "Processing document: idp/textract/receipts/receipt_21.png\n",
      "Processing document: idp/textract/receipts/receipt_22.png\n",
      "Processing document: idp/textract/receipts/receipt_23.png\n",
      "Processing document: idp/textract/receipts/receipt_24.png\n",
      "Processing document: idp/textract/receipts/receipt_25.png\n",
      "Processing document: idp/textract/receipts/receipt_26.png\n",
      "Processing document: idp/textract/receipts/receipt_27.png\n",
      "Processing document: idp/textract/receipts/receipt_28.png\n",
      "Processing document: idp/textract/receipts/receipt_29.png\n",
      "Processing document: idp/textract/receipts/receipt_3.png\n",
      "Processing document: idp/textract/receipts/receipt_30.png\n",
      "Processing document: idp/textract/receipts/receipt_31.png\n",
      "Processing document: idp/textract/receipts/receipt_32.png\n",
      "Processing document: idp/textract/receipts/receipt_33.png\n",
      "Processing document: idp/textract/receipts/receipt_34.png\n",
      "Processing document: idp/textract/receipts/receipt_35.png\n",
      "Processing document: idp/textract/receipts/receipt_36.png\n",
      "Processing document: idp/textract/receipts/receipt_37.png\n",
      "Processing document: idp/textract/receipts/receipt_38.png\n",
      "Processing document: idp/textract/receipts/receipt_39.png\n",
      "Processing document: idp/textract/receipts/receipt_4.png\n",
      "Processing document: idp/textract/receipts/receipt_40.png\n",
      "Processing document: idp/textract/receipts/receipt_41.png\n",
      "Processing document: idp/textract/receipts/receipt_42.png\n",
      "Processing document: idp/textract/receipts/receipt_43.png\n",
      "Processing document: idp/textract/receipts/receipt_44.png\n",
      "Processing document: idp/textract/receipts/receipt_45.png\n",
      "Processing document: idp/textract/receipts/receipt_46.png\n",
      "Processing document: idp/textract/receipts/receipt_47.png\n",
      "Processing document: idp/textract/receipts/receipt_48.png\n",
      "Processing document: idp/textract/receipts/receipt_49.png\n",
      "Processing document: idp/textract/receipts/receipt_5.png\n",
      "Processing document: idp/textract/receipts/receipt_50.png\n",
      "Processing document: idp/textract/receipts/receipt_51.png\n",
      "Processing document: idp/textract/receipts/receipt_52.png\n",
      "Processing document: idp/textract/receipts/receipt_53.png\n",
      "Processing document: idp/textract/receipts/receipt_54.png\n",
      "Processing document: idp/textract/receipts/receipt_55.png\n",
      "Processing document: idp/textract/receipts/receipt_56.png\n",
      "Processing document: idp/textract/receipts/receipt_57.png\n",
      "Processing document: idp/textract/receipts/receipt_58.png\n",
      "Processing document: idp/textract/receipts/receipt_59.png\n",
      "Processing document: idp/textract/receipts/receipt_6.png\n",
      "Processing document: idp/textract/receipts/receipt_60.png\n",
      "Processing document: idp/textract/receipts/receipt_61.png\n",
      "Processing document: idp/textract/receipts/receipt_62.png\n",
      "Processing document: idp/textract/receipts/receipt_63.png\n",
      "Processing document: idp/textract/receipts/receipt_64.png\n",
      "Processing document: idp/textract/receipts/receipt_65.png\n",
      "Processing document: idp/textract/receipts/receipt_66.png\n",
      "Processing document: idp/textract/receipts/receipt_67.png\n",
      "Processing document: idp/textract/receipts/receipt_68.png\n",
      "Processing document: idp/textract/receipts/receipt_69.png\n",
      "Processing document: idp/textract/receipts/receipt_7.png\n",
      "Processing document: idp/textract/receipts/receipt_70.png\n",
      "Processing document: idp/textract/receipts/receipt_71.png\n",
      "Processing document: idp/textract/receipts/receipt_72.png\n",
      "Processing document: idp/textract/receipts/receipt_73.png\n",
      "Processing document: idp/textract/receipts/receipt_74.png\n",
      "Processing document: idp/textract/receipts/receipt_75.png\n",
      "Processing document: idp/textract/receipts/receipt_76.png\n",
      "Processing document: idp/textract/receipts/receipt_77.png\n",
      "Processing document: idp/textract/receipts/receipt_78.png\n",
      "Processing document: idp/textract/receipts/receipt_79.png\n",
      "Processing document: idp/textract/receipts/receipt_8.png\n",
      "Processing document: idp/textract/receipts/receipt_80.png\n",
      "Processing document: idp/textract/receipts/receipt_81.png\n",
      "Processing document: idp/textract/receipts/receipt_82.png\n",
      "Processing document: idp/textract/receipts/receipt_83.png\n",
      "Processing document: idp/textract/receipts/receipt_84.png\n",
      "Processing document: idp/textract/receipts/receipt_85.png\n",
      "Processing document: idp/textract/receipts/receipt_86.png\n",
      "Processing document: idp/textract/receipts/receipt_87.png\n",
      "Processing document: idp/textract/receipts/receipt_88.png\n",
      "Processing document: idp/textract/receipts/receipt_89.png\n",
      "Processing document: idp/textract/receipts/receipt_9.png\n",
      "Processing document: idp/textract/receipts/receipt_90.png\n",
      "Processing document: idp/textract/receipts/receipt_91.png\n",
      "Processing document: idp/textract/receipts/receipt_92.png\n",
      "Processing document: idp/textract/receipts/receipt_93.png\n",
      "Processing document: idp/textract/receipts/receipt_94.png\n",
      "Processing document: idp/textract/receipts/receipt_95.png\n",
      "Processing document: idp/textract/receipts/receipt_96.png\n",
      "Processing document: idp/textract/receipts/receipt_97.png\n",
      "Processing document: idp/textract/receipts/receipt_98.png\n",
      "Processing document: idp/textract/receipts/receipt_99.png\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool_results = [pool.apply_async(textract_extract_text, (document,data_bucket)) for document in docs]\n",
    "labeled_collection = [res.get() for res in pool_results]\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f94fa1-2b3d-4554-a9ae-e51cf417dbf1",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Prepare a CSV training dataset for Amazon Comprehend custom classifier training<a id=\"step3\"></a>\n",
    "\n",
    "Now that we have text extracted from our documents and have also labeled them, we will create the training data in order to train an [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html). Let's take a look at the labeled data. We have 100 sample of each document, so we should have about 300 rows of labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "318adcdd-fe82-41db-bae2-ee1d216058a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank-statements</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank-statements</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank-statements</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-statements</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bank-statements</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>receipts</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>receipts</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>receipts</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>receipts</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>receipts</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                           document\n",
       "0    bank-statements  Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...\n",
       "1    bank-statements  Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...\n",
       "2    bank-statements  Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...\n",
       "3    bank-statements  Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...\n",
       "4    bank-statements  Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...\n",
       "..               ...                                                ...\n",
       "295         receipts  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...\n",
       "296         receipts  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...\n",
       "297         receipts  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...\n",
       "298         receipts  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...\n",
       "299         receipts  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_df = pd.DataFrame(labeled_collection, columns=['label','document'])\n",
    "comprehend_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a3fa1-6130-4e08-a45e-ee3b3287cd1c",
   "metadata": {},
   "source": [
    "uploading the training dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a056a3f-9498-418c-a3ee-2334e7ddf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Comprehend training data to S3\n",
    "key='idp/comprehend/comprehend_train_data.csv'\n",
    "\n",
    "comprehend_df.to_csv(\"comprehend_train_data.csv\", index=False, header=False)\n",
    "s3.upload_file(Filename='comprehend_train_data.csv', \n",
    "               Bucket=data_bucket, \n",
    "               Key=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a6504-84ef-48fb-9c1a-b3912cf1664c",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Create Amazon Comprehend Classification training job <a id=\"step4\"></a>\n",
    "\n",
    "Once we have a labeled dataset ready we are going to create and train a [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f16b-f0eb-4f40-92fd-99d5ff582cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document classifier\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "document_classifier_name = 'Sample-Doc-Classifier-IDP'\n",
    "document_classifier_version = 'Sample-Doc-Classifier-IDP-v1\n",
    "document_classifier_arn = ''\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    create_response = comprehend.create_document_classifier(\n",
    "        InputDataConfig={\n",
    "            'DataFormat': 'COMPREHEND_CSV',\n",
    "            'S3Uri': f's3://{data_bucket}/{key}'\n",
    "        },\n",
    "        DataAccessRoleArn=role,\n",
    "        DocumentClassifierName=document_classifier_name,\n",
    "        VersionName=document_classifier_version,\n",
    "        LanguageCode='en',\n",
    "        Mode='MULTI_CLASS'\n",
    "    )\n",
    "    \n",
    "    document_classifier_arn = create_response['DocumentClassifierArn']\n",
    "    \n",
    "    print(f\"Comprehend Custom Classifier created with ARN: {document_classifier_arn}\")\n",
    "except Exception as error:\n",
    "    if error.response['Error']['Code'] == 'ResourceInUseException':\n",
    "        print(f'A classifier with the name \"{document_classifier_name}\" already exists.')\n",
    "        document_classifier_arn = f'arn:aws:comprehend:{region}:{account_id}:document-classifier/{document_classifier_name}/version/{document_classifier_version}'\n",
    "        print(f'The classifier ARN is: \"{document_classifier_arn}\"')\n",
    "    else:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93e871-1ff7-450c-aaec-0595e870554a",
   "metadata": {},
   "source": [
    "This job can take ~30 minutes to complete. Once the training job is completed move on to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d03ae4a-2e82-4088-8a00-d4207cab22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'document_classifier_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store document_classifier_arn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690d9f0-cb49-4b1c-9de9-c3fdffb32acd",
   "metadata": {},
   "source": [
    "Checking status of classification training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba6dd9d-9bfc-4673-b117-a16a9686288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:08:21 : Custom document classifier: TRAINED\n",
      "CPU times: user 310 ms, sys: 33 ms, total: 343 ms\n",
      "Wall time: 15min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through and wait for the training to complete . Takes up to 10 mins \n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "jobArn = create_response['DocumentClassifierArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn = jobArn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{current_time} : Custom document classifier: {status}\")\n",
    "    \n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1354a-cc99-408e-9109-2f0151f95384",
   "metadata": {},
   "source": [
    "# Step 5: Classify documents with Amazon Comprehend custom classifier <a id=\"step5\"></a>\n",
    "\n",
    "In this step we will use Amazon Comprehend custom classification model to classify sample documents. We will use `start_document_classification_job` API to launch an asynchronous job to classify the documents. This API supports documents in their native format (PDF/PNG/JPG/TIF) and can use Amazon Textract behind the scenes to read the text from the documents and subsequently determine the document class. Let's start by uploading our sample documents to the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635e03e-0b61-4494-9326-464ac559c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir samples\n",
    "!aws s3 cp s3://idp-sample-docs/comprehend/mixedbag ./samples/mixedbag --recursive\n",
    "!aws s3 cp s3://idp-sample-docs/comprehend/textract ./samples/textract --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd270e5b-ec18-4511-8e60-9b23fe898d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp ./samples s3://{data_bucket}/idp/comprehend --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7f07a-defa-4b65-b8bf-0617076e85ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "jobname = f'doc-classification-job-{uuid.uuid1()}'\n",
    "print(f'Starting Comprehend Classification job {jobname} with model {document_classifier_arn}')\n",
    "\n",
    "response = comprehend.start_document_classification_job(\n",
    "    JobName=jobname,\n",
    "    DocumentClassifierArn=document_classifier_arn,\n",
    "    InputDataConfig={\n",
    "        'S3Uri': f's3://{data_bucket}/idp/comprehend/mixedbag/',\n",
    "        'InputFormat': 'ONE_DOC_PER_FILE',\n",
    "        'DocumentReaderConfig': {\n",
    "            'DocumentReadAction': 'TEXTRACT_DETECT_DOCUMENT_TEXT',\n",
    "            'DocumentReadMode': 'FORCE_DOCUMENT_READ_ACTION'\n",
    "        }\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': f's3://{data_bucket}/idp/comprehend/doc-class-output/'\n",
    "    },\n",
    "    DataAccessRoleArn=role\n",
    ")\n",
    "\n",
    "response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76138609-8088-4f5b-8fb6-fef43ae7a285",
   "metadata": {},
   "source": [
    "## Check status of the classification job\n",
    "\n",
    "The code block below will check the status of the classification job. If the job completes then it will download the output predictions. The output is a zip file which will contain the inference result for each of the documents being classified. The zip will also contain the output of the Textract operation performed by Amazon Comprehend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2991cf-0298-4e08-bbb4-a2d7b529b491",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb17cd-621e-4f03-b37a-bc103019d103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop through and wait for the training to complete . Takes up to 10 mins \n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "classify_response=response\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "documents=[]\n",
    "\n",
    "while time.time() < max_time:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    describe_job = comprehend.describe_document_classification_job(\n",
    "        JobId=classify_response['JobId']\n",
    "    )\n",
    "    status = describe_job[\"DocumentClassificationJobProperties\"][\"JobStatus\"]\n",
    "\n",
    "    print(f\"{current_time} : Custom document classifier Job: {status}\")\n",
    "    \n",
    "    if status == \"COMPLETED\" or status == \"FAILED\":\n",
    "        if status == \"COMPLETED\":\n",
    "            classify_output_file = describe_job[\"DocumentClassificationJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "            print(f'Output generated - {classify_output_file}')\n",
    "            !mkdir -p classification-output\n",
    "            !aws s3 cp {classify_output_file} ./classification-output\n",
    "            \n",
    "            opfile = os.path.basename(classify_output_file)\n",
    "            # open file\n",
    "            file = tarfile.open(f'./classification-output/{opfile}')\n",
    "            # extracting file\n",
    "            file.extractall('./classification-output')\n",
    "            file.close()\n",
    "            \n",
    "            for file in os.listdir('./classification-output'):\n",
    "                if file.endswith('.out'):\n",
    "                    with open(f'./classification-output/{file}', 'r') as f:\n",
    "                        documents.append(dict(file=file, classification_output=json.load(f)['Classes']))        \n",
    "        else:\n",
    "            print(\"Classification job failed\")\n",
    "            print(describe_job)\n",
    "        break\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5adb7e6f-38c6-4bc5-9efd-6c29daa00725",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>DocType</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_6.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_10.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_7.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_1.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_4.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>document_0.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>document_8.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>document_5.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>document_2.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>document_3.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>document_9.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Document          DocType  Confidence\n",
       "0    document_6.png         invoices      1.0000\n",
       "1   document_10.png         receipts      1.0000\n",
       "2    document_7.png         invoices      0.9999\n",
       "3    document_1.png  bank-statements      1.0000\n",
       "4    document_4.png  bank-statements      1.0000\n",
       "5    document_0.png  bank-statements      1.0000\n",
       "6    document_8.png         receipts      1.0000\n",
       "7    document_5.png         invoices      0.9999\n",
       "8    document_2.png  bank-statements      1.0000\n",
       "9    document_3.png  bank-statements      1.0000\n",
       "10   document_9.png         receipts      0.9999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification = []\n",
    "for doc in documents:\n",
    "    document = []    \n",
    "    classes_df = pd.DataFrame(doc['classification_output'])\n",
    "    result = classes_df.iloc[classes_df['Score'].idxmax()]\n",
    "    document.extend([doc['file'].replace(\".out\",\"\"), result.Name, result.Score])    \n",
    "    classification.append(document)\n",
    "    \n",
    "doc_class_df = pd.DataFrame(classification, columns = ['Document', 'DocType', 'Confidence'])\n",
    "doc_class_df                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ef646-2e7b-4e7c-bf69-2742eb3a6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ada00714-300d-417f-94c3-94cb3c779ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: document_6.png...\n",
      "Uploading: document_10.png...\n",
      "Uploading: document_7.png...\n",
      "Uploading: document_1.png...\n",
      "Uploading: document_4.png...\n",
      "Uploading: document_0.png...\n",
      "Uploading: document_8.png...\n",
      "Uploading: document_5.png...\n",
      "Uploading: document_2.png...\n",
      "Uploading: document_3.png...\n",
      "Uploading: document_9.png...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['idp/comprehend/classified-docs/bank-statements/document_0.png',\n",
       " 'idp/comprehend/classified-docs/bank-statements/document_1.png',\n",
       " 'idp/comprehend/classified-docs/bank-statements/document_2.png',\n",
       " 'idp/comprehend/classified-docs/bank-statements/document_3.png',\n",
       " 'idp/comprehend/classified-docs/bank-statements/document_4.png',\n",
       " 'idp/comprehend/classified-docs/invoices/document_5.png',\n",
       " 'idp/comprehend/classified-docs/invoices/document_6.png',\n",
       " 'idp/comprehend/classified-docs/invoices/document_7.png',\n",
       " 'idp/comprehend/classified-docs/receipts/document_10.png',\n",
       " 'idp/comprehend/classified-docs/receipts/document_8.png',\n",
       " 'idp/comprehend/classified-docs/receipts/document_9.png']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root='idp/comprehend/classified-docs'\n",
    "\n",
    "def upload_classified_docs(filename,prefix):\n",
    "    document = os.path.basename(filename)\n",
    "    key = f'{root}/{prefix}/{document}'\n",
    "    print(f'Uploading: {filename}...')\n",
    "    res = s3.upload_file(Filename=f\"./samples/mixedbag/{filename}\", \n",
    "                   Bucket=data_bucket, \n",
    "                   Key=key)\n",
    "    return f'{root}/{prefix}/{document}'\n",
    "\n",
    "doc_class_df['s3path'] = doc_class_df.apply(lambda row : upload_classified_docs(row['Document'],row['DocType']), axis = 1)\n",
    "\n",
    "#verify uploads\n",
    "[objects['Key'] for objects in s3.list_objects(Bucket=data_bucket, Prefix=f\"{root}/\")['Contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1bcc9-b31b-4195-b455-5bfeb30e94bc",
   "metadata": {},
   "source": [
    "... text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43e11bc5-499d-4af5-bb52-2317a26b9435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>DocType</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>s3path</th>\n",
       "      <th>DocText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_6.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/invoices/docume...</td>\n",
       "      <td>INVOICE\\nAnyCompany Manufacturing\\nDATE\\nDec 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_10.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/receipts/docume...</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_7.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>idp/comprehend/classified-docs/invoices/docume...</td>\n",
       "      <td>INVOICE\\nAnyCompany Hardware\\nDATE\\nDec 09, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_1.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/bank-statements...</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_4.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/bank-statements...</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>document_0.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/bank-statements...</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>document_8.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/receipts/docume...</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>document_5.png</td>\n",
       "      <td>invoices</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>idp/comprehend/classified-docs/invoices/docume...</td>\n",
       "      <td>INVOICE\\nAnyCompany Hardwares LLC\\nDATE\\nMay 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>document_2.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/bank-statements...</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>document_3.png</td>\n",
       "      <td>bank-statements</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>idp/comprehend/classified-docs/bank-statements...</td>\n",
       "      <td>Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>document_9.png</td>\n",
       "      <td>receipts</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>idp/comprehend/classified-docs/receipts/docume...</td>\n",
       "      <td>THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Document          DocType  Confidence  \\\n",
       "0    document_6.png         invoices      1.0000   \n",
       "1   document_10.png         receipts      1.0000   \n",
       "2    document_7.png         invoices      0.9999   \n",
       "3    document_1.png  bank-statements      1.0000   \n",
       "4    document_4.png  bank-statements      1.0000   \n",
       "5    document_0.png  bank-statements      1.0000   \n",
       "6    document_8.png         receipts      1.0000   \n",
       "7    document_5.png         invoices      0.9999   \n",
       "8    document_2.png  bank-statements      1.0000   \n",
       "9    document_3.png  bank-statements      1.0000   \n",
       "10   document_9.png         receipts      0.9999   \n",
       "\n",
       "                                               s3path  \\\n",
       "0   idp/comprehend/classified-docs/invoices/docume...   \n",
       "1   idp/comprehend/classified-docs/receipts/docume...   \n",
       "2   idp/comprehend/classified-docs/invoices/docume...   \n",
       "3   idp/comprehend/classified-docs/bank-statements...   \n",
       "4   idp/comprehend/classified-docs/bank-statements...   \n",
       "5   idp/comprehend/classified-docs/bank-statements...   \n",
       "6   idp/comprehend/classified-docs/receipts/docume...   \n",
       "7   idp/comprehend/classified-docs/invoices/docume...   \n",
       "8   idp/comprehend/classified-docs/bank-statements...   \n",
       "9   idp/comprehend/classified-docs/bank-statements...   \n",
       "10  idp/comprehend/classified-docs/receipts/docume...   \n",
       "\n",
       "                                              DocText  \n",
       "0   INVOICE\\nAnyCompany Manufacturing\\nDATE\\nDec 2...  \n",
       "1   THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...  \n",
       "2   INVOICE\\nAnyCompany Hardware\\nDATE\\nDec 09, 20...  \n",
       "3   Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...  \n",
       "4   Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...  \n",
       "5   Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...  \n",
       "6   THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...  \n",
       "7   INVOICE\\nAnyCompany Hardwares LLC\\nDATE\\nMay 2...  \n",
       "8   Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...  \n",
       "9   Page 1 of 5 03/02/2022\\nDC 1090001004290\\nAnyC...  \n",
       "10  THE AIML StORE\\n1234 SOMEWHERE RD\\nPOWAY, CALI...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textractprettyprinter.t_pretty_print import Textract_Pretty_Print, get_string\n",
    "import json\n",
    "\n",
    "def get_text(doc):\n",
    "    with open(f'classification-output/amazon-textract-output/{doc}/1', 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    text = get_string(textract_json=obj, output_type=[Textract_Pretty_Print.LINES])\n",
    "    return text\n",
    "\n",
    "doc_class_df['DocText'] = doc_class_df.apply(lambda row : get_text(row['Document']), axis = 1)\n",
    "doc_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fc790-b6fe-4341-a608-c51ad6b4a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_class_df.to_csv('extracted_doc.csv')\n",
    "#Upload dataframe as csv to S3\n",
    "s3.upload_file(Filename='extracted_doc.csv', \n",
    "               Bucket=data_bucket, \n",
    "               Key=f'idp/comprehend/extracted/extracted_doc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff61633-c35f-4133-817e-412e67762264",
   "metadata": {},
   "source": [
    "# step 6: Amazon Augmented AI <a id=\"step6\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f683a-ac6c-42b4-a8d6-c898d433eb5e",
   "metadata": {},
   "source": [
    "### Create Human Task UI\n",
    "\n",
    "Create a human task UI resource, giving a UI template in liquid html. This template will be rendered to the human workers whenever human loop is required.\n",
    "\n",
    "Below we've provided a simple demo template that is compatible with AWS Comprehend's Detect Sentiment API input and response.\n",
    "\n",
    "For over 70 pre built UIs, check: https://github.com/aws-samples/amazon-a2i-sample-task-uis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7f054a2-e230-44e4-8018-a1610defda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client('sagemaker', region)\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "OUTPUT_PATH = f's3://{data_bucket}/idp/doc-class-output/comprehend-custom-workflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "200fae1b-36bc-4443-bb2e-bb981b4bc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "    <crowd-classifier\n",
    "      name=\"sentiment\"\n",
    "      categories=\"['invoice', 'receipt', 'bank-statement']\"\n",
    "      initial-value=\"{{ task.input.initialValue }}\"\n",
    "      header=\"What sentiment does this text convey?\"\n",
    "    >\n",
    "      <classification-target>\n",
    "        {{ task.input.taskObject }}\n",
    "      </classification-target>\n",
    "      \n",
    "      <full-instructions header=\"Sentiment Analysis Instructions\">\n",
    "        <p><strong>Invoice</strong> If the extracted text is from a Invoice</p>\n",
    "        <p><strong>Receipt</strong> If the extracted text is from a Receipt</p>\n",
    "        <p><strong>Bank Statement</strong> If the extracted text is from a Bank Statement</p>\n",
    "      </full-instructions>\n",
    "\n",
    "      <short-instructions>\n",
    "       Choose the primary sentiment that is expressed by the text. \n",
    "      </short-instructions>\n",
    "    </crowd-classifier>\n",
    "</crowd-form>\n",
    "\"\"\"\n",
    "\n",
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08118db-d4c4-4ffc-9a97-fa154a90a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'ui-comprehend-' + str(uuid.uuid4()) \n",
    "\n",
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dee4fe-1e3d-4158-92d5-77ae7b21e115",
   "metadata": {},
   "source": [
    "### Creating the Flow Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e89e4-f96a-4c90-a859-2fc6a81bd408",
   "metadata": {},
   "source": [
    "We assume you have already created a workteam for simplicity, you can create a workteam using the AWS console follow this [guide](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-create-private-console.html). Or you can create a cognito Idp to use the API for workteam creation. \n",
    "After creating the workteam copy the workteam ARN from `labelling workforces` under `Ground truth` in the SageMaker navigation pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8683c7d8-a8fb-459b-a02c-1c36c9f1c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN= \"<YOUR_WORKTEAM>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dafef226-b15d-494d-8d4a-9f1899217a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'fd-comprehend-demo-' + str(uuid.uuid4()) \n",
    "\n",
    "create_workflow_definition_response = sagemaker.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn= ROLE,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Identify the sentiment of the provided text\",\n",
    "            \"TaskTitle\": \"Detect Sentiment of Text\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04fd2e45-8710-44a4-92b5-5359a60b4d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active\n",
      "Flow Definition is active\n"
     ]
    }
   ],
   "source": [
    "# Describe flow definition - status should be active\n",
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39a0da53-45ec-499d-be3a-95d98c144323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blurb: \"document_6.png\"\n",
      "SentimentScore of 1.0, invoices is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_10.png\"\n",
      "SentimentScore of 1.0, receipts is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_7.png\"\n",
      "SentimentScore of 0.9999, invoices is less than the threshold of 1\n",
      "Starting human loop with name: 14a2982a-3c74-41c5-a7ae-b7bbce078172  \n",
      "\n",
      "Processing blurb: \"document_1.png\"\n",
      "SentimentScore of 1.0, bank-statements is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_4.png\"\n",
      "SentimentScore of 1.0, bank-statements is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_0.png\"\n",
      "SentimentScore of 1.0, bank-statements is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_8.png\"\n",
      "SentimentScore of 1.0, receipts is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_5.png\"\n",
      "SentimentScore of 0.9999, invoices is less than the threshold of 1\n",
      "Starting human loop with name: 005cfdf5-53f0-4e99-8cf0-d09b658f1aa7  \n",
      "\n",
      "Processing blurb: \"document_2.png\"\n",
      "SentimentScore of 1.0, bank-statements is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_3.png\"\n",
      "SentimentScore of 1.0, bank-statements is above threshold of 1\n",
      "No human loop created. \n",
      "\n",
      "Processing blurb: \"document_9.png\"\n",
      "SentimentScore of 0.9999, receipts is less than the threshold of 1\n",
      "Starting human loop with name: 2af521da-a87b-416a-a2a7-34c347b8c539  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_loops_started = []\n",
    "SENTIMENT_SCORE_THRESHOLD = 1\n",
    "for _, blurb in doc_class_df.iterrows():\n",
    "    # Call AWS Comprehend's Detect Sentiment API\n",
    "    response = blurb[\"Confidence\"]\n",
    "    \n",
    "    print(f'Processing blurb: \\\"{blurb[\"Document\"]}\\\"')\n",
    "    \n",
    "    # Our condition for when we want to engage a human for review\n",
    "    if (response < SENTIMENT_SCORE_THRESHOLD):\n",
    "    \n",
    "        humanLoopName = str(uuid.uuid4())\n",
    "        inputContent = {\n",
    "            \"initialValue\": blurb[\"DocType\"][:-1],\n",
    "            \"taskObject\": blurb[\"DocText\"]\n",
    "        }\n",
    "        start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(inputContent)\n",
    "            }\n",
    "        )\n",
    "        human_loops_started.append(humanLoopName)\n",
    "        print(f'SentimentScore of {response}, {blurb[\"DocType\"]} is less than the threshold of {SENTIMENT_SCORE_THRESHOLD}')\n",
    "        print(f'Starting human loop with name: {humanLoopName}  \\n')\n",
    "    else:\n",
    "        print(f'SentimentScore of {response}, {blurb[\"DocType\"]} is above threshold of {SENTIMENT_SCORE_THRESHOLD}')\n",
    "        print('No human loop created. \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84af74-0482-433f-af91-eb2b101c9254",
   "metadata": {},
   "source": [
    "The task will be completed after a human reviews the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a750-339a-4b0b-8a01-9772c4bfdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f'HumanLoop Name: {human_loop_name}')\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9bc49-68af-498b-ac7b-2a75da098f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
